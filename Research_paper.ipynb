{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdad9850-fa09-405d-b744-84b2d2a7b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_infos():\n",
    "    ## 0: Code , 1:Weight , 2: height, 3:age, 4: gender\n",
    "    dss = np.genfromtxt(\"data_subjects_info.csv\",delimiter = ',')\n",
    "    dss = dss[1:]\n",
    "    return dss\n",
    "\n",
    "def create_time_series(num_features,num_act_labels,num_gen_labels,label_codes,trial_codes):\n",
    "    dataset_columns = num_features + num_act_labels + num_gen_labels\n",
    "    ds_list = get_infos()\n",
    "    train_data = np.zeros((0,dataset_columns))\n",
    "    test_data = np.zeros((0,dataset_columns))\n",
    "    for i, sub_id in enumerate(ds_list[:,0]):\n",
    "        for j, act in enumerate(label_codes):\n",
    "            for trial in trial_codes[act]:\n",
    "                fname = 'A_DeviceMotion_data/'+act+'_'+str(trial)+'/sub_'+str(int(sub_id))+'.csv'\n",
    "                raw_data=pd.read_csv(fname,index_col=0)\n",
    "                raw_data.drop(raw_data.columns[raw_data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "                unlabel_data=raw_data.values\n",
    "                label_data=np.zeros((len(unlabel_data),dataset_columns))\n",
    "                label_data[:,:-(num_act_labels + num_gen_labels)] = unlabel_data\n",
    "                label_data[:,label_codes[act]] = 1\n",
    "                label_data[:,-(num_gen_labels)] = int(ds_list[i,4])\n",
    "                \n",
    "                if trial>10:\n",
    "                    test_data=np.append(test_data,label_data,axis=0)\n",
    "                else:\n",
    "                    train_data=np.append(train_data,label_data,axis=0)\n",
    "    \n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4022320e-fcc9-468a-b8d2-f22806b0c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Time-Seires: (621973, 17)\n",
      "Shape of Test Time-Series: (145687, 17)\n"
     ]
    }
   ],
   "source": [
    "#labeled time_series from dataset of \"(A)DeviceMotion_data\"\n",
    "\n",
    "num_features=12\n",
    "num_act_labels=4 #dws,ups,wlk,jog\n",
    "num_gen_labels = 1 # 0(female)/1(male)\n",
    "label_codes={\"dws\":num_features, \"ups\":num_features+1, \"wlk\":num_features+2, \"jog\":num_features+3}\n",
    "trial_codes = {\"dws\":[1,2,11], \"ups\":[3,4,12], \"wlk\":[7,8,15], \"jog\":[9,16]} \n",
    "\n",
    "train_ts,test_ts=create_time_series(num_features, num_act_labels, num_gen_labels, label_codes, trial_codes)\n",
    "print(\"Shape of Training Time-Seires:\", train_ts.shape)\n",
    "print(\"Shape of Test Time-Series:\", test_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd812bf-065c-4773-876e-0979837095fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sectioning Training and Test datasets: shape of each section will be: ( 12 x 50 )\n",
      "Training Data has been standardized:\n",
      " the mean is =  -0.01695311674756102  ; and the std is =  0.8714768261722013\n",
      " Shape of Training Sections: (61728, 12, 50)\n",
      " Shape of Test Sections: (14098, 12, 50)\n"
     ]
    }
   ],
   "source": [
    "def time_series_to_section(dataset, num_act_labels, num_gen_labels, sliding_window_size, step_size_of_sliding_window, standardize = False, **options):\n",
    "    data = dataset[: , 0:-(num_act_labels+num_gen_labels)]\n",
    "    act_labels = dataset[: , -(num_act_labels+num_gen_labels):-(num_gen_labels)]\n",
    "    gen_labels = dataset[: , -(num_gen_labels)]\n",
    "    mean = 0\n",
    "    std = 1\n",
    "    \n",
    "    if standardize:\n",
    "        ## Standardize each sensorâ€™s data to have a zero mean and unity standard deviation.\n",
    "        ## As usual, we normalize test dataset by training dataset's parameters \n",
    "        if options:\n",
    "            mean = options.get(\"mean\")\n",
    "            std = options.get(\"std\")\n",
    "        else:\n",
    "            mean = data.mean(axis=0)\n",
    "            std = data.std(axis=0)\n",
    "            print(\"Training Data has been standardized:\\n the mean is = \",str(mean.mean()),\" ; and the std is = \",str(std.mean()))            \n",
    "  \n",
    "        data -= mean\n",
    "        data /= std\n",
    "    else:\n",
    "        print(\"----> Without Standardization.....\")\n",
    "\n",
    "    ## We want the Rows of matrices show each Feature and the Columns show time points.\n",
    "    data = data.T\n",
    "            \n",
    "    size_features = data.shape[0]\n",
    "    size_data = data.shape[1]\n",
    "    number_of_secs = round(((size_data - sliding_window_size)/step_size_of_sliding_window))\n",
    "            \n",
    "    ##  Create a 3D matrix for Storing Snapshots  \n",
    "    secs_data = np.zeros((number_of_secs , size_features , sliding_window_size ))\n",
    "    act_secs_labels = np.zeros((number_of_secs, num_act_labels))\n",
    "    gen_secs_labels = np.zeros(number_of_secs)\n",
    "    \n",
    "    k=0    \n",
    "    for i in range(0 ,(size_data)-sliding_window_size  , step_size_of_sliding_window):\n",
    "        j = i // step_size_of_sliding_window\n",
    "        if(j>=number_of_secs):\n",
    "            break\n",
    "        if(gen_labels[i] != gen_labels[i+sliding_window_size-1]): \n",
    "            continue\n",
    "        if(not (act_labels[i] == act_labels[i+sliding_window_size-1]).all()): \n",
    "            continue    \n",
    "        secs_data[k] = data[0:size_features, i:i+sliding_window_size]\n",
    "        act_secs_labels[k] = act_labels[i].astype(int)\n",
    "        gen_secs_labels[k] = gen_labels[i].astype(int)\n",
    "        k = k+1\n",
    "    secs_data = secs_data[0:k]\n",
    "    act_secs_labels = act_secs_labels[0:k]\n",
    "    gen_secs_labels = gen_secs_labels[0:k]\n",
    "    \n",
    "    return secs_data, act_secs_labels, gen_secs_labels, mean, std\n",
    "##________________________________________________________________\n",
    "\n",
    "\n",
    "## This Variable Defines the Size of Sliding Window\n",
    "## ( e.g. 100 means in each snapshot we just consider 100 consecutive observations of each sensor) \n",
    "sliding_window_size = 50 # 50 Equals to 1 second for MotionSense Dataset (it is on 50Hz samplig rate)\n",
    "## Here We Choose Step Size for Building Diffrent Snapshots from Time-Series Data\n",
    "## ( smaller step size will increase the amount of the instances and higher computational cost may be incurred )\n",
    "step_size_of_sliding_window = 10 \n",
    "print(\"Sectioning Training and Test datasets: shape of each section will be: (\",num_features,\"x\",sliding_window_size,\")\")\n",
    "train_data, act_train_labels, gen_train_labels, train_mean, train_std = time_series_to_section(train_ts.copy(),\n",
    "                                                                                               num_act_labels,\n",
    "                                                                                               num_gen_labels,\n",
    "                                                                                               sliding_window_size,\n",
    "                                                                                               step_size_of_sliding_window,\n",
    "                                                                                               standardize = True)\n",
    "\n",
    "test_data, act_test_labels, gen_test_labels, test_mean, test_std = time_series_to_section(test_ts.copy(),\n",
    "                                                                                          num_act_labels,\n",
    "                                                                                          num_gen_labels,\n",
    "                                                                                          sliding_window_size,\n",
    "                                                                                          step_size_of_sliding_window,\n",
    "                                                                                          standardize = True,\n",
    "                                                                                          mean = train_mean, \n",
    "                                                                                          std = train_std)\n",
    "print(\" Shape of Training Sections:\", train_data.shape)\n",
    "print(\" Shape of Test Sections:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9de438-5798-4485-8792-352ceb52524c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33bf19a-1c0b-48fd-af9b-708378f12150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "import torchvision.models as models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d65be03-c458-4c77-9ff3-8c3342b6d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of Training Sections: (61728, 12, 50, 1)\n",
      " Shape of Test Sections: (14098, 12, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.expand_dims(train_data,axis=3)\n",
    "test_data = np.expand_dims(test_data,axis=3)\n",
    "print(\" Shape of Training Sections:\", train_data.shape)\n",
    "print(\" Shape of Test Sections:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ba2722-c8c5-45c0-8c6b-07e761962b8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-862bf8aec744>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-862bf8aec744>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    self.linear_1=nn.linear(\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "num_train,height,width,channel = train_data.shape\n",
    "metrics = ['acc']\n",
    "conv_depth_1 = 50\n",
    "kernel_size_1=5\n",
    "kernel_size_2=3\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_0 = nn.Conv2d(in_channels=height,out_channels=conv_depth_1,kernel_size=(1,kernel_size_1),padding='valid')\n",
    "        self.conv_1 = nn.Conv2d(in_channels=conv_depth_1,out_channels=convo_depth_1,kernel_size=(1,kernel_size_2),padding='same')\n",
    "        self.linear_1=nn.linear("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48f75262-9ab1-4f46-a68d-4fea4e9e7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,3,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1594ec2-9dcd-4820-a4a8-9d56717750cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61728, 12, 50, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0d1dd72-9285-4f09-86ae-eb6d1e642a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "num_train,height,width,channel = train_data.shape\n",
    "print(height)\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dda05e-79c9-432b-8da0-42a44bd180b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
